% !TeX spellcheck = eu_ES
\documentclass[eu]{ifirak}

\usepackage{amsmath,latexsym,amssymb,natbib}
\usepackage{listings}
\usepackage{ifcommands,subfigure}
\usepackage[T1]{fontenc}
\usepackage{tcolorbox}

\newcommand{\zkk}{\guillemotleft}
\newcommand{\skk}{\guillemotright}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\eng}[1]{\textit{#1}}
\newcommand{\hgl}[1]{\zkk #1\skk\ }

\begin{document}
\ikasturtea{2014/2015}
\irakasgaia{Bilaketa Heuristikoak}
\title{BHLN: Populazioan oinarritutako algoritmoak}
\date{}
\irakaslea{Borja Calvo, Usue Mori}
\author{Borja Calvo, Usue Mori}


\tel{943 01 50 13}
\mail{borja.calvo@ehu.es}

<<echo=FALSE , purl=FALSE>>=
## This code is for wrapping long outputs
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
knitr::opts_chunk$set(linewidth=100) 
knit_theme$set("earendel")
@


\maketitle

\begin{abstract}
Aurreko kapituluan soluzio bakarrean oinarritzen diren zenbait algoritmo ikusi ditugu. Algoritmo hauek oso portaera ezberdina izan arren, badute ezaugarri komuna: bilaketa prozesua soluzio batetik bestera mugitzen da, soluzioak banan-banan aztertuz. Beraz, oso algoritmo egokiak dira bilaketa espazioaren eskualdea interesgarriak arakatzeko --bilaketa areagotzeko, alegia--. Alabaina, hainbat kasutan emaitza honak lortzeko bilaketa dibertsifikatzea ere beharrezkoa izan liteke. Izan ere, bilaketa lokalean oinarrizen diren algoritmo batzuk dibertsifikatzeko zenbait estrategia darabilte; honen adibide nabarmena tabu bilaketaren epe-luzeko memoria da.

Kapitulu honetan soluzioak banan-banakako azterketa alde batera utzita, multzoka erabiltzeari ekingo diogu, horixe baita, hain juxtu, populazioetan oinarritzen diren algoritmoen filosofia. Une oro, soluzio bakar bat izan beharrean soluzio multzo bat izango dugu. Testu inguru batzuetan multzo horri \hgl{soluzio-populazio} deritzo eta, hortik, algoritmo hauen izena. Bilaketa prozesuan multzo hori aldatuz joango da, helburu funtzioaren gidapean.

Bi dira, nagusiki, populazioetan oinarritzen diren algoritmoen hurbilketak: algoritmo ebolutiboak eta \eng{swarm intelligence}. Lehenengo kategoriako algoritmoek, teknika ezberdinak erabiliz, populazioa eboluzionarazten dute, geroz eta soluzio hobeak izan ditzan. Adibiderik ezagunena algoritmo genetikoak dira. Bigarren algoritmo mota, berriz, zenbait animalien portaeran oinarritzen da. Hauen arteko adibiderik ezagunenak, esate baterako, inurriek, janaria eta inurritegiaren arteko distantziarik motzena topatzeko darabilten mekanismoa imitatu egiten du.

Kapitulua bi zatitan banaturik dago. Lehenengoan algoritmo ebolutioben eskema orokorra ikusi ondoren, algoritmo genetikoak \cite{holland1975} eta EDAk \cite{larranaga2002,lozano2006} aurkezten dira. Bigarren zatian \eng{swarm intelligence} \cite{blum2008} arloan proposaturiko bi algoritmo aztertuko dira.
\end{abstract}


\section{Algoritmo Ebolutiboak}\label{sec:ebolutiboak}
1859. urtean Charles R. Darwin \eng{On the Origin of the Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life} liburua argitaratu zuen. Tituluak berak adierazten duen bezala, liburu honetan Darwinek hautespen naturalaren teoria aurkeztu zuen. 

Eboluzioaren teoriak dioenez, belaunalditik belaunaldira zenbait mekanismoen bidez --mutazioak, esate baterako-- aldaketak sortzen dira. Aldaketa batzuei esker indibiduoak hobeto egokitzen dira beraien inguruneari eta, ondorioz, bizirik mantentzeko eta, batez ere, ugaltzeko probabilitateak handitzen dira. Era berean, noski, aldaketa batzuk kaltegarriak izan daitezke, bizitzeko aukerak murriztuz. Kontutan hartuz aipatutako aldaketak heredatu egiten direla, ezaugarri onak generazioz generazio pasatzen dira; kaltegarriak direnek, ostera, galtzeko joera izaten dute. Mekanismo honen bidez, espezieak beraien ingurunera egokitzeko gai dira.

Hirurogeigarren hamarkadan ikertzaileek Darwinaren lana inspiraziotzat hartu zuten optimizazio metahuristikoak diseinatzeko; gaur egun konputazio zientziaren arlo oso bat da konputazio ebolutiboa. Atal honetan bi algoritmo mota aztertuko ditugu, algoritmo genetiko klasikoak \cite{holland1975} eta EDAk (\eng{Estimation of Distribution Algorithms}) \cite{larranaga2002, lozano2006}.

Algoritmo ebolutibotan bi dira giltzarri diren elementuak: hautespena eta soluzio berrien sorkuntza. Naturan bezala, soluzio onak aukeratuko ditugu hurrengo belaunaldiara pasatzeko. Soluzio txarrenak deusestatzen ditugunez, populazioa osatzeko soluzio berriak behark dira; sorkuntza prozesua aukeratu ditugu soluzioak hartzen ditu abia-puntutzat.

\begin{figure}[t]
\centering
\includegraphics[height=0.2\textheight]{./Irudiak/AEB}
\caption{Algoritmo ebolutiboen eskema orokorra}
\label{fig:alg.evol}
\end{figure}


Diferentziak diferentzia, algoritmo ebolutiboen eskema orokorra defini daiteke (ikusi \ref{fig:alg.evol} irudia). Algoritmoaren sarrera-puntua hasierako populazioa izango da; populazio horretatik abiatuz, algoritmoa begizta nagusian sartzen da, non bi pausu tartekatzen dira. Lehenik, uneko populazioan dauden soluzioetatik batzuk aukeratzen dira. Ondoren, soluzio horiek erabiliz populazio berri bat sortzen da. Begizta nagusia etengabekoa denez, zanbait irizpide erabiltzen dira algoritmoa amaitutzat emateko.

Hurrengo ataletan eskema orokor hau nola gauzatzen den ikusiko dugu. Dena dela, zenbait pausu orokorrak diren legez, algoritmo konkretuak ikusi aurretik aztertuko ditugu. 

\subsection{Urrats orokorrak}

Badaude zenbait pausu algoritmo ezberdinetan oso antzerakoak direnak. Izan ere, ikusiko ditugun algoritmoen arteko diferentzia nagusia soluzio berrien osaketan datza. Atal honetan gaionontzeko urratsak aztertuko ditugu eta hurrengo ataletan soluzioen sorkuntzari ekingo diogu.

\subsubsection{Populazioaren hasieraketa}

Hasierako populazioa da algoritmoaren abia-puntua eta, hortaz, bere sorkuntza oso pausu garrantzitsua da. Izan ere, askotan garrantzi gutxiegi ematen zaio pausu honi, nahiz eta oso eragin handia izan azken emaitzan.

Algoritmoen xedea soluzio honak topatzea izanda, pentsa dezakegu hasierako populazio on bat sortzeko soluzio onak behar ditugula; alabaina, dibertsitatea soluzioen kalitatea bezain garrantzitsua da. Izan ere, oso soluzio antzerakoak baldin baditugu, onak izan arren, populazioaren eboluzioa oso zaila izango da eta algoritmoaren konbergentzia goiztiarra gertatuko da. 

Hortaz, hasierako populazioa sortzean bi aspektu izan behar ditugu kontutan: kalitatea eta dibertsitatea. Kasu gehienetan ausazko hasieraketa erabiltzen da lehen populazioa sortzeko, hau da, ausazko soluzioak sortzen dira populazioa osatu arte. Estrategia hau erabiliz dibertsitate handiko populazioa sortuko dugu, baina kalitatea ez da handia izango. 

Populazioa guztiz ausaz sortzen badugu dibertsitatea handia izan arren, badaude beste estrategia batzuk --sasiausazkoak direnak-- dibertstiatea maximizatzeko. Hori dela eta, proposatu dira beste prozedura batzuk populazioak sasi-ausaz sortzeko dibertsitatea maximizatuz. Esate baterako dibertsifikazio sekuentzialean soluzio berri bat onartzeko populazioan dauden soluzioekiko distantzia minimo batera egon behar da. Adibide moduan, demagun 10 tamainako populazio bat sortu nahi dugula non soluzioak 25 tamainako bektore bitarrak diren. Dibertsitatea bermatzeko beraien arteko Hamming distantzia minimoa 10 izan behar dela inposa dezakegu. Jarraian dagoen kodeak horrelako populazioak sortzen ditu:

<<ham_dis , prompt=TRUE, echo=-1 , message=FALSE , cache=TRUE>>=
set.seed(1)
hamm.distance <- function (v1 , v2){
  d <- sum(v1!=v2)
  return(d)
}

rnd.binary <- function(n){
  return (runif(n) > 0.5)
}
@

Lehenik, Hamming distantzia neurtzeko eta ausazko bektore bitarrak sortzeko funtzioak sortzen ditugu. Gero, soluzioak asuaz sortzen ditugu eta, distantzia minimoko baldintza bete ezean, deusestatzen dira; prozedura nahi ditugun soluzio kopurua lortu arte exekutatzen da. 

<<seq_divers , prompt=TRUE, message=FALSE, cache=TRUE>>=
sol.size <- 25
pop.size <- 10
min.distance <- 10
population <- list(rnd.binary (sol.size))
while (length(population) < pop.size){
  new.sol <- rnd.binary(sol.size)
  distances <- lapply(population , FUN = function(x) hamm.distance (x,new.sol))  
  if (min(unlist(distances)) <= min.distance)
    population[[length(population) + 1]] <- new.sol
}

@


Hau prozedura ez da bat ere eraginkorra, zenbait kasutan soluzio asko sortu beharko batitugu populazioa sortu arte. Beste alternatiba bat dibertsifikazio paraleloa da. Kasu honetan bilaketa espazioa zatitu egiten da eta azpi-espazio bakoitzetik ausazko soluzio bat erauzten da.

Orain arte dibertsitateari bakarrik erreparatu diogu. Hasierako popuazioaren kalitatea handitu nahi izanez gero, hasieraketa heuristikoak erabil daitezke. Hau lortzeko era sinple bat, GRASP algoritmoetan ausazko soluzioak sortzeko erabiltzen diren prozedurak erabiltzea da. Ikus dezagun adibide bat TSP problemarako; lehenik, Bavierako hirien problema kargatuko dugu.

<<heur_init_1 , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE, cache=TRUE>>=
library("metaheuR")
url <- system.file("bays29.xml.zip" , package = "metaheuR")
cost.matrix <- tsplib.parser(url)
@

Orain, \code{tsp.greedy} funtzioan oinarrituta ausazko soluzio onak sortzeko funtzio bat definitzen dugu.

<<heur_init_2 , prompt=TRUE, message=FALSE, cache=TRUE>>=
rnd.sol <- function(cl.size = 5){
  tsp.greedy(cmatrix = cost.matrix , cl.size = cl.size)
}
@

\code{tsp.greedy} funtzioak TSP-rako algoritmo eraikitzaile bat inplementatzen du; pausu bakoitzean, uneko hiritik zein hirira mugituko garen erabakitzen da. Hiria aukeratzeko gertuen dauden \code{cl.size} hirietatik --5, gure kasuan-- bat ausaz aukeratzen da. Populazioa sortzeko funtzio hau erabiliko dugu.

<<heur_init_3 , prompt=TRUE, message=FALSE, cache=TRUE>>=
pop.size <- 25
population <- lapply (1:pop.size , FUN = function(x) rnd.sol())
@

Hautagaien zerrenda problemaren tamainaraino handitzen badugu, pausu bakoitzean aukera guztietatik bat ausaz hartuko dugu, hots, guztiz ausazkoak diren soluzioak sortuko ditugu. Hau eginda populazioaren kalitatea goiko kodearekin lortutakoa baino txarragoa izango da:

<<heur_init_4 , prompt=TRUE, message=FALSE, cache=TRUE>>=
rnd.population <- lapply (1:pop.size , 
                          FUN = function(x) rnd.sol(cl.size = ncol(cost.matrix)))
tsp <- tsp.problem(cost.matrix)
eval.heur <- unlist(lapply(population , FUN = tsp$evaluate))
eval.rnd <- unlist(lapply(rnd.population , FUN = tsp$evaluate))
@


Bi populazioen ebaluazioak \eng{boxplot} baten bidez aldera dezakegu.

<<plot_heur_vs_rnd , echo = -1, cache=TRUE , warning=FALSE, prompt=TRUE , cache=TRUE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=8 , fig.height=4>>=
library("ggplot2")
df <- rbind (data.frame (Method = "Heuristic" , Evaluation = eval.heur) , 
             data.frame (Method = "Random" , Evaluation = eval.rnd))
ggplot(df , aes(x = Method , y = Evaluation)) + geom_boxplot()
@

\begin{figure}[t]
\centering
\includegraphics[height=0.33\textheight]{./Irudiak/plot_heur_vs_rnd-1}
\caption{Ausazko hasieraketa eta hasieraketa heuristikoaren arteko konparaketa. Y ardatzak metodo bakoitzarekin sortutako soluzioen \eng{fitness}-a adierazten du.}\label{fig:heur_vs_rnd_init_pop}
\end{figure}

\ref{fig:heur_vs_rnd_init_pop} irudiak lortutako emaitzak erakusten ditu; argi eta garbi ikus daiteke heuristikoa erabiliz sortutako soluzioak hobeak direla.

Soluzioak sortzeko metodoak ez ezik, populazioaren tamainak ere badu eragin handia azken emaitzan. Izan ere, populazioaren tamaina egokitu behar den oso parametro garrantzitsua izango da. Populazioak txikiegiak badira, dibertsitatea mantentzea oso zaila izango da eta, hortaz, belaunaldi gutxitan algoritmoa konbergituko da. Beste aldetik, populazioa handiegia bada, konbergentzia abiadura motelduko da baina kostu konputazionala handituko da; hurrengo atalean adibide baten bidez ikusiko dugu hau. Ez dago irizpide finkorik tamaina ezartzeko, problema bakoitzeko egokitu beharko da. Edonola ere, irizpide orokor gisa esan dezakegu populazio azkar konbergitzen badu --hots, soluzioen arteko distantzia azkar txikitzen bada--, konponbidea populazioare tamaina handitzea izan daitekeela. 


\subsubsection{Hautespena}

Algoritmo ebolutibotan populazioaren murriztea urrats garrantzitsua da, populazioaren eboluzioa kontrolatzen duen prozesua baita. Orokorrean, populazioan dauden soluziorik onenak hautatzea interesatuko zaigu eta hori da, hain zuzen, gehien erabiltzen den hautespena; bakarrik soluziorik onenak aukeratzen dituenez, hautespen honi \zkk elitista\skk\ deritzo. Soluzio onak aukeratzea garrantzitsua da baina, dibertsitatea mantentzearren, tarteka soluzio txarrak ere sartzea komenigarria izan daiteke. Hau zuzenea egiterik egon arren, badaude beste hautespen metodoak era probabilistikoan egiten dutenak.

Erruleta-hautespena,  (\textit{Roulette Wheel selection}, ingelesez) deritzon estrategian soluzioak erruleta batean kokatzen dira; soluzio bakoitzari dagokion erruletaren zatia bere ebaluazioarekiko proportzionala izango da. \ref{fig:roulette} irudian ikus daitekeen bezala, erruleta jaurtitzen den bakoitzean indibiduo bat hautatzen da; hautatua izateko probabilitatea erruleta zatiaren tamaina eta, hortaz, indibiduoen ebaluazioarekiko proportzionala da. 

Indibiduo bat baino gehiago aukeratu behar baldin badugu, behar ditugun erruletaren jaurtiketak egin ditzakegu. Alabaina, honek alborapenak sor ditzake; efektu hau saihesteko erruletan puntu bakar bat markatu beharrean (gezia, \ref{fig:roulette} irudian), behar ditugun puntuak finkatu ahal ditugu. Era honetan, jaurtiketa bakar batekin nahikoa da behar ditugun indibiduo guztiak hautatzeko. Teknika hau populazioa murrizteko zein indibiduoak gurutzatzeko hautespenean erabil daiteke.

\eng{Fitness}aren magnitudea problema eta, are gehiago, instantzien araberakoa da. Hori dela eta, probabilitateak zuzenean helburu funtzioaren balioarekiko proportzionalak badira, oso distribuzio radikalak izan ditzakegu. Arazo hau ekiditeko, helburu funtzioaren balioa zuzenean erabili beharrean soluzioen ranking-a erabili ahal da.

\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/roulette}
\caption{Erruleta-hautespena. Indibiduo bakoitzaren erruletaren zatia bere ebaluazioarekiko proportzionala da. Erruleta jaurtitzen den bakoitzean indibiduo bat aukeratzen da, bere \eng{fitness}arekiko proportzionala den probabilitatearekin. Adibidean, 2. indibiduoa da hautatu dena.}
\label{fig:roulette}
\end{figure}

Beste hautespen probabilistiko bat Lehiaketa-hautespena da. Estrategia honetan hautespena bi pausutan egiten da. Lehenengo urratsean indibiduo guztietatik azpi-multzo bat aukeratzen da, guztiz ausaz (ebaluazioa kontutan hartu barik). Ondoren, aukeratu ditugun indibiduoetatik onena hautatzen dugu. Azpi-multzoa ausaz aukeratzen denez, bertan oso soluzio txarrak leudeke eta, hortaz, nahiz eta onena hautatu, soluzioa txarra izan daiteke.


\subsubsection{Gelditze Irizpideak}

Lehen apiatu bezala, algoritmo ebolutioben begizta nagusia amaigabea da eta, beraz, algoritmoa gelditzeko irizpideren bat ezarri behar dugu, bilaketari amaiera emateko. Hurbilketarik sinpleena irizpide estatikoak erabiltzea da, hala nola, denbora maximoa ezartzea, ebaluazioak mugatzea, etab.

Gelditzeko irizpideak dinamikoak ere izan daitezke, eboluzioaren prozesuari erreparatzen badiogu. Balunaldiz balaundi populazioan dauden soluzioak geroz eta hobeak dira eta, aldi berean, populazioaren dibertsitatea murrizten da. Beste era batean esanda, populazioko soluzioek soluzio bakar batera konbergitzeko joera dute.

Hori gertatzen denean eboluzioa moteltzen denez, popluzaioaren dibertsitatea gelditzeko irizpide gisa erabili ahal da. Dibertsitatea soluzioei zein beraien \eng{fitness}-ari erreparatuz neur daiteke. Esate baterako, soluzioen arteko distatzia neurtzerik badago, indibiduoen arteko bataz besteko distantzia minimo bat ezar dezakegu.

\subsubsection{Algoritmo Genetikoak}

Atal honetan algoritmo genetikotan \cite{holland1975} soluzio berriak algoritmo genetikoetan nola sortzen diren ikusiko dugu. Algoritmo hauek naturan espeziekin gertatzen dena imitatzen dute. Era honetan, zenbait paralelismo ezar daitezke:

\begin{itemize}
\item Espezieen indibiduoak = Problemaren soluzioak
\item Indibiduoen egokitasuna --\eng{fitness}-a, alegia-- = Soluzioaren ebaluazioa
\item Espeziearen populazioa = Soluzio multzoa
\item Ugalketa = Soluzio berrien sorkuntza
\end{itemize}

Beraz, algoritmo genetikoetan soluzio berriak sortzeko indibiduen ugalketan oinarrituko gara.  Ugalketa prozesuaren xedea zenbait indibiduo emanda --bi, normalean--, indibiduo gehiago sortzea da. Ohikoena prozesu hau bi pausutan banatzea da: soluzioen gurutzaketa eta mutazioa. Lehenaren helburua \hgl{guraso}-soluzioek duten ezaugarriak soluzio berriei pasatzea da. Bigarrenarena, berriz, sortutako soluzioetan ezaugarri berriak sartzea da. Jarraian soluzioak maneiatzeko bi operadore hauek aztertuko ditugu.

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\linewidth]{./Irudiak/point_crossover}
\caption{Gurutzatze-operadoreak bektoreen bidezko kodeketarekin erabiltzeko}
\label{fig:point_crossover}
\end{figure}

\subsubsection{Gurutzaketa} 

Bi soluzio --edo gehiago-- gurutzatzen ditugunean euren propietateak sortutako soluzioei transmititzea da gure helburua. Hori lortzeko, soluzioei operadore mota berezi bat aplikatuko diegu, \hgl{gurutze-operadorea} --\eng{crossover}, ingelesez--. Operadore honek soluzioen kodeketarekin dihardu eta, beraz, operadorea hautatzean soluzioak nola adieratzen dugun aintzat hartu beharko dugu. 

Badaude zenbait operadore kodeketa klasikoekin erabil daitezkeenak. Ezagunena puntu bakarreko gurutzatzea -- \eng{one-point crossover}, ingelesez -- deritzona da. Demagun soluzioak bektoreen bidez kodetzen ditugula. Bi soluzio, $s_1$ eta $s_2$ parametro gisa hartuz, operadore honek beste bi soluzio berri sortzen ditu. Horretarako, lehenik eta behin, ausazko posizio bat $i$ aukeratu behar da. Gero, lehenengo soluzio berria $s_1$ soluziotik lehenengo $i$ elementuak eta $s_2$ soluziotik beste gainontzekoak kopiatuz sortuko dugu. Era berean, bigarren soluzio berria $s_2$-tik lehenengo elementuak eta besteak $s_1$-etik kopiatuz sortuko dugu.  \ref{fig:point_crossover} irudiaren ezkerraldean adibide bat ikus daiteke. Irudiak ideia nola orokor daitekeen ere erakusten du, puntu bakar bat erabili beharrean bi, hiru, etab. puntu erabiliz.

Operadore hau \code{metaheuR} liburutegian inplementaturik dago, \code{k.point.crossover} funtzioan. Ikus ditzagun adibide batzuk:

<<k_point_cross , prompt=TRUE, echo=-1 , message=FALSE, cache=TRUE>>=
set.seed(666)
A.sol <- rep("A" , 10)
B.sol <- rep("B" , 10)
A.sol
B.sol
k.point.crossover(A.sol , B.sol , 1)
k.point.crossover(A.sol , B.sol , 5)
k.point.crossover(A.sol , B.sol , 20)
@

Azken adibidean ikus daitekeen bezala, $n$ tamainako bektore bat izanik gehienez $n-1$ puntu erabil ditzakegu operadore honetan; edonola ere, balio handiagoa erabiltzen badugu funtzioak abisu bat emango du eta parametroa bere balio maximoan ezarriko du. Balio maximoarekin jatorrizko soluzioen elementuak tartekatuko dira; operadore honi \eng{uniform crossover} deritzo.

Erabiliko dugun puntu kopurua eragin handia izan dezake algoritmoaren performantzian eta, hortaz, egokitu behar den algoritmoaren parametrotzat hartu beharko genuke. 

Ikusitako operadorea nahiko orokorra da, ia edozen bektoreari aplikatu ahal baitzaio. Hala eta guztiz ere, kodeketa batzuetan operadore bereziak erabil daitezke\cite{gwiazda2006}. Esate baterako, bektore errealak baldin baditugu, bi bektore harturik era ezberdinetan konbina daitezke; adibidez, bataz bestekoa kalkulatuz. Ikus dezagun operadore hau nola inplementa daitekeen R-n:

<<mean_cross , prompt=TRUE, message=FALSE, cache=TRUE>>=
mean.crossover <- function (sol1 , sol2){
  new.solution <- (sol1 + sol2) / 2
  return(new.solution)
}

s1 <- runif(10)
s2 <- runif(10)
s1
s2
mean.crossover(s1 , s2)
@

Permutazioak ere bektoreak dira baina, kasu honetan, \eng{k point crossover} operadorea ezin da erabili, permutazioetan ditugun murrizketak direla eta. Hortaz, permutazioak gurutatzeko operadore bereziak behar ditugu. Aukera asko izan arren \cite{talbi2009}, hemen puntu bakarreko gurutzatze operadorearen baliokidea ikusiko dugu. Lehenik eta behin, ikus dezagun zergatik puntu bakarreko operadorea ezin da zuzenean aplikatu permutazioei. Izan bitez bi permutazio, $s_1 = 12345678$ eta $s_2=87654321$, eta gurutzatze puntu bat, $i=3$. Lehenengo soluzio berria lortzeko $s_1$ soluziotik lehendabiziko hiru posizioak kopiatuko ditugu, hau da, $123$, eta besteak $s_2$-tik, hots, $54321$. Hortaz, lortutako soluzioa $s^\prime = 12354321$ izango zen baina, zoritxarrez, hau ez da permutazio bat.

Nola saihestu daiteke arazo hau? Soluzio sinple bat hauxe da: lehenengo posizioak zuzenean soluzio batetik kopiatzea; besteak zuzenean beste soluziotik kopiatu beharrean, ordena bakarrik erabiliko dugu. Hau da, soluzio berria sortzeko $s_1$-etik lehenengo 3 elementuak kopiatuko ditugu, $123$, eta falta direnak, $45678$, $s_2$-an agertzen den ordenean kopiatuko ditugu, hots, $87654$. Emaitza, beraz, $s^\prime = 12387654$ izango da eta beraz, orain bai, permutazio bat lortu dugu. Era berean, beste soluzio berri bat sor daiteke $s_2$-tik lehenengo hiru posizioak kopiatuz ($876$) eta beste gainontzeko guztiak $s_1$-an duten ordenean kopiatuz ($12345$); beste soluzioa, beraz, $87612345$ izango da. Operadore honi \hgl{Order crossover} deritzo eta \code{metaheuR} liburutegian inplementaturik dago, \code{order.crossover} funtzioan \footnote{Funtzio honetan inplementatuta dagoena \eng{2-point crossover} operadorea da. Hau da, bi puntu erabiltzen dira eta, soluzioak eraikitzeko, bi puntuen artean dagoena soluzio batetik kopiatu ondore, beste gainontzeko elementuak beste soluzioan duden ordenean erabiltzen dira.}.

<<order_cross , prompt=TRUE, message=FALSE , echo=-1 , warning=FALSE, cache=TRUE>>=
set.seed(5)
sol1 <- random.permutation(10)
sol2 <- identity.permutation(10)
as.numeric(sol1)
as.numeric(sol2)
new.solutions <- order.crossover(sol1 , sol2)
as.numeric(new.solutions[[1]])
as.numeric(new.solutions[[2]])
@


\subsubsection{Mutazioa} 

Naturan bezala, gure populazioa eboluzionatzeko dibertsitatea garrantzitsua da. Hori dela eta, behin soluzio berriak lortuta gurutzatze-operadorearen bidez, soluzio hauetan ausazko aldaketak eragin ohi da; aldaketa hauek mutazio operadorearen bidez sortzen dira. 

Mutazioaren kontzeptua ILS algoritmoko perturbazioaren antzerakoa da; izan ere, operadore berdinak erabil daitezke. Esate baterako, permutazio bat mutatzeko ausazko trukaketak erabil ditzakegu. ILS-an bezala, algoritmoa diseinatzean erabaki behar dugu zenbat aldaketak sortuko ditugun -- adibidean, zenbat posizio trukatuko ditugun --.

Mutazio operadorea aukeratzean --eta baita diseinatzean ere-- hainbat gauza hartu behar dira kontuan. Hasteko, soluzioen bideragarritasuna mantentzea garrantzitsua da, hau da, mutazio operadorea bideragarria den soluzio bati aplikatuz gero, emaitzak soluzio bideragarria izan behako luke. Bestaldetik, bilaketa prozesua soluzio bideragarrien espazio osoa arakatzeko gaitasuna izan beharko luke eta hori bermatzeko mutazio operadoreak edozein soluzio sortzeko gai izan behar du. Hau da, edozein soluzio hartuta mutazio operadorearen bidez beste edozein soluzioa sortzeak posible izan beharko luke. Amaitzeko, lokaltasuna ere mantendu behar da --alegia, mutazioak eragindako aldaketa txikia izan behar da--, bestela gurasoengandik heredatutako ezaugarriak galdu egingo dira.

Mutazio operadorea era probabilistikoan aplikatzen da; hau da, ez zaie soluzio guztiei aplikatzen. Hortaz, mutazioari lotutako bi parametro izango ditugu: mutazio probabilitatea eta mutazioaren magnitudea.


\begin{ifalgorithm}[t]
\begin{ifpseudo}{Algoritmo Genetikoak}
\item \In\ \texttt{evaluate}, \texttt{select\_reproduction}, \texttt{select\_replacement}, \texttt{cross}, \texttt{mutate} eta \texttt{!stop\_criterion} operadoreak
\item \In\ \texttt{init\_pop} hasierako populazioa
\item \In\ \texttt{mut\_prob} mutazio probabilitatea
\item \Out\ \texttt{best\_sol}
\item \texttt{pop=init\_pop}
\item \While \texttt{stop\_criterion} \Do
\item \T{\texttt{evaluate(pop)}}
\item \T{\texttt{ind\_rep = select\_reproduction(pop)}}
\item \T{\texttt{new\_ind = reproduce(ind\_rep)}}
\item \T{\textbf{for} \textbf{each} \texttt{n} in \texttt{new\_ind} \Do}
\item \TT{\texttt{mut\_prob} probabilitatearekin egin \texttt{mutate(n)}}
\item \T{\Done}
\item \T{\texttt{evaluate(new\_ind)}}
\item \T{\If \texttt{new\_ind} multzoan \texttt{best\_ind} baino hobea den soluziorik badago}
\item \TT{Eguneratu \texttt{best\_sol}}
\item \T{\EIf}
\item \T{\texttt{pop=select\_replacement(pop,new\_ind)}}
\item \Done
\end{ifpseudo}
\caption{Algoritmo genetikoen sasikodea}\label{alg:algoritmo_genetikoak}
\end{ifalgorithm}

Algoritmo genetiko orokorra \ref{alg:algoritmo_genetikoak} irudian ikus daiteke. Algoritmoan dagoen sasikodea \code{basic.genetic.algorithm} funtzioan inplementaturik dago. Ikus dezagun nola erabil daitekeen funtzio hau \eng{graph coloring} problema bat ebazteko. Lehenik, ausazko grafo bat sortuko dugu problemaren instantzia sortzeko.

<<ga_graph_col_1 , prompt=TRUE, message=FALSE , echo=-2 , warning=FALSE, cache=TRUE>>=
library(igraph)
set.seed(5)
n <- 50
rnd.graph <- aging.ba.game(n = n , pa.exp = 2 , 
                           aging.exp = 0, m = 3 , directed = F)
gcp <- graph.coloring.problem (graph = rnd.graph)
@

Orain zenbait elementu definitu behar ditugu. Lehenengoa, hasierako populazioa izango da. Populazioa sortzeko bere tamaina ezarri behar dugu. Hau algoritmoaren parametro garrantzitsu bat denez, bi balio erabiliko ditugu, emaitzak alderatzeko: $n$ eta $10n$. Soluzioak ausaz sortuko ditugu eta, gero, bideragarriak ez badira, zuzenduko ditugu.

<<ga_graph_col_2 , prompt=TRUE, message=FALSE , warning=FALSE, cache=TRUE>>=
n.pop.small <- n
n.pop.big <- 10*n
levels <- paste("C" , 1:n , sep = "")
rnd.sol <- function(x){
  sol <- factor(paste("C" , sample(1:n , size = n , replace = TRUE) , 
                      sep = "") , levels = levels)
  return(gcp$correct(sol))
}
pop.small <- lapply(1:n.pop.small , FUN = rnd.sol)
pop.big   <- lapply(1:n.pop.big , FUN = rnd.sol)
@

Hasierako populazioaz gain, ondoko parametro hauek ezarri behar ditugu:

\begin{itemize}
\item Hautespen operadoreak - Hurrengo belaunaldira pasatuko diren soluzioak aukeratzeko hautespen elitista erabiliko dugu, populazio erdia aukeratuz; zein soluzio gurutzatuko diren aukeratzeko, berriz, lehiaketa hautespena erabiliko dugu.
\item Mutazioa - Soluzioak mutatzeko \code{factor.mutation} soluzio erabiliko dugu. Funtzio honek zenbait posizio ausaz aukeratzen ditu eta bere balioak ausaz aldatzen ditu. Funtzioak parametro bat du, \code{ratio}, zeinek aldatuko diren posizioen ratioa adierazten duen. Gure kasuan 0.1 balioa erabiliko dugu, alegia, \%10 posizio aldatuko dira mutazioa aplikatzen denean. Zein probabilitatearekin mutatuko ditugun soluzioak ere finkatu behar da, \code{mutation.rate} parametroaren bidez; gure kasuan probabilitatea bat zati populazioaren tamaina izango da.
\item Gurutzaketa - Soluzioak gurutzatzeko \eng{k point crossover} erabiliko, $k = 2$ finkatuz. 
\item Beste parametro batzuk - Algoritmo genetikoaren parametroaz gain, beste bi parametro finaktuko ditugu, \code{non.valid = 'discard'}, bideraezina diren soluzioak baztertu behar direla adierazteko, eta \code{resources}, gelditze irizpidea finkatzeko ($5n^2$ ebaluazio kopuru maximoa erabiliko dugu).
\end{itemize}

\begin{figure}[t]
\subfigure[Algoritmo genetikoaren progresioa]{
\includegraphics[width=0.65\textwidth] {./Irudiak/ga_graph_col_3-1}
}\qquad
\subfigure[Lortutako soluzioa]{
\includegraphics[width=0.30\textwidth] {./Irudiak/ga_graph_col_4-1}
}\\
\caption{Algoritmo genetikoaren progresioa \eng{graph coloring} problema batean, bi poulazio tamaina ezberdin erabiliz. Ezkerrean, populazio tamaina handiarekin lortutako soluzioa ikus daiteke.}\label{fig:ga_progress}
\end{figure}

Jarraian parametro hauek erabiliz algoritmo genetikoa exekutatzeko kodea dago.


<<ga_graph_col_3, prompt=TRUE, cache=TRUE, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
args <- list()
args$evaluate             <- gcp$evaluate
args$initial.population   <- pop.small
args$select.subpopulation <- elitist.selection
args$selection.ratio      <- 0.5
args$select.cross         <- tournament.selection
args$mutate               <- factor.mutation
args$ratio                <- 0.1
args$mutation.rate        <- 1 / length(args$initial.population)
args$cross                <- k.point.crossover
args$k                    <- 2
args$non.valid            <- 'discard'
args$resources            <- cresource(evaluations = 5*n^2)

bga.small <- do.call(basic.genetic.algorithm , args)

args$initial.population   <- pop.big
args$mutation.rate        <- 1 / length(args$initial.population)

bga.big <- do.call(basic.genetic.algorithm , args)
plot.progress(list("Big population" = bga.big , "Small population" = bga.small) , 
              size = 1.1) + labs(y = "Average fitness") + aes(linetype = Group)
@


<<ga_graph_col_4, prompt=TRUE, cache=TRUE , echo = FALSE , message=FALSE , warning=FALSE  , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=5 , fig.height=5>>=
best.big <- unlist(optima(bga.big)[[1]])
gcp$plot(best.big,node.size=15,label.cex=0.75)
@


\ref{fig:ga_progress} irduian bi populazio erabiliz bilaketaren progresioa ikus daiteke. Populazioa txikia denean algoritmoak oso azkar konbergitzen du 19 kolore darabiltzan soluzio batera. Populazioko soluzio gehienak oso antzerakoak direnean soluzio berriak sortzeko bide bakarra mutazioa da, baina prozesu hori oso motela denez, grafikan ikus daiteke soluzioen bataz besteko \eng{fitness}a ez dela aldatzen. 

Populazioaren tamaina handitzen dugunean konbergentzia zailagoa da eta grafikan ikus daiteke helbur funtzioaren balioaren eboluzioa motelagoa izan arren, lortutako soluzioa hobea dela.

\begin{figure}[t]
\centering
\includegraphics[width=0.75\textwidth] {./Irudiak/ga_mut_rate-1}
\caption{Mutazioaren probabilitatearen eragina algoritmo genetikoaren emaitzan. Irudian ikus daitekeen bezala, soluziorik onenak ematen duen balioa 0.5 inguruan dagoena da (zehazki, 0.6). }\label{fig:ga_mutrate}
\end{figure}

Populazioaren tamaina ez ezik, beste hainbat parametro eragin handia izan dezakete algoritmoaren emaitzan; esate baterako, mutazioaren probabilitatea. Adibide gisa, popluazio tamaina txikia erabiliz mutazio probabilitate ezberdinak erabiliko ditugu, eta, ondoren, bakoitzarekin lortutako emaitzak alderatuko ditugu.

<<ga_mut_rate, prompt=TRUE, cache=TRUE, echo=-1, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
set.seed(10)
args$initial.population   <- pop.small
args$verbose              <- FALSE
args$resources            <- cresource(evaluations = n^2)

test.mutprob <- function (rate){
  args$mutation.rate        <- rate
  res <- do.call(basic.genetic.algorithm , args)
  evaluation(res)
}

ratios <- seq(0,1,0.2)
evaluations <- sapply(ratios , FUN = test.mutprob)

df <- data.frame("Mutation_rate" = ratios , "Fitness" = evaluations)
ggplot(df , aes(x=Mutation_rate , y = Fitness)) + geom_line() + geom_point(size = 5) + 
  labs(x = "Mutation rate")
@


\ref{fig:ga_mutrate} irudian konparaketaren emaitzak ikus daitezke. Grafikoan agerian dago probabilitate txikiegiak zein handiegiak kaltegarriak direla bilaketarako; izan ere, probabilitate egokiena 0.5 ingurukoa da. Edonola ere, kontutan hartu behar da probabilitate txikien kasuan emaitzak txarrak direla konbergentzia goiztiarra dugulak baina, probabilitate handiekin berrriz, arazoa justo kontrakoa izan daiteke, alegia, jarri dugun muga dela eta populazioa konbergitzen duela. Hau egiaztatzeko, errepika dezakezu goiko experimentua ebaluazio kopuru maximoa handituz.

\subsection{Estimation of Distribution Algorithms}

Algoritmo genetikoetan uneko populazioa indibiduo berriak sortzeko erabiltzen da. Prozesu honetan, naturan inspiratutako operadoreen bidez burutzen dena, populazioan dauden ezaugarriak mantentzea espero dugu. Edonola ere, prozesua korapilatsua izan daiteke. Hori dela eta, zenbait ikertzaile ideia hau hartu eta ikuspen matematikotik birformulatu zuten; gurutzatze-operadoreak eta mutazioa erabili beharrean, eredu probabilistikoak erabiltzea proposatu zuten, populazioaren \hgl{esentzia} kapturatzeko helburuarekin. Hauxe da, EDA -- \eng{Estimation of Distribution Algorithms} -- algoritmotan erabiltzen den ideia.

Algoritmo genetikoen eta EDA motako algoritmoen artean dagoen diferentzia bakarra indibiduo berriak sortzean dago. Gurutzatzea eta mutazioa erabili beharrean, uneko populazioa eredu probabilistiko bat \hgl{ikasteko} erabiltzen da. Ondoren, eredu hori laginduko dugu nahi ditugun indibiduo adina sortzeko.

EDA algoritmoen gakoa, beraz, eredu probabilistikoa da. Ildo honetan, esan beharra dago eredua soluzioen kodeketari lotuta dagoela, soluzio adierazpide bakoitzari probabilitate bat esleitu beharko diolako. 

Konplexutasun ezberdineko eredu probabilistikoen erabilera proposatu da literaturan, baina badago hurbilketa sinple bat oso hedatua dagoena: UMDA -- \eng{Univariate Marginal Distribution Algorithm} --. Kasu honetan soluzioaren osagaiak -- bektore bat bada, bere posizioak -- independenteak direla suposatuko dugu eta, hortaz, osagai bakoitzari dagokion probabilitate marjinala estimatu beharko dugu. Gero, indibiduoak sortzean osagaiak banan-banan aukeratuko ditugu probabilitate hauek kontutan hartuz. 

Probabilitate marjinalak maneiatzeko \code{metaheuR} paketeko \code{UnivariateMarginals} objektua erabil dezakegu. Bere erabilera ikusteko, populazio txiki bat sortuko dugu eta probabilitate marginalak kalkulatuko ditugu. 

<<UMDA_1, cache=TRUE , echo=-1 , prompt=TRUE, message=FALSE , warning=FALSE>>=
set.seed(1)
population <- lapply(1:5 , FUN = function(x) factor(sample(1:3 , 10 , replace = TRUE) ,
                                                    levels = 1:3))
@

Orain, \code{univariateMarginals} funtzioa erabiliz probabilitate marginalak kalkulatuko ditugu:

<<UMDA_2, cache=TRUE, prompt=TRUE, message=FALSE , warning=FALSE>>=
model <- univariateMarginals(data = population)

do.call(rbind , population)
model@prob.table
@

Sortutako soluzioek 10 elementu dituzte eta populazioak 5 soluzio ditu. Lehenengo elementuari erreparatzen badiogu, 5 soluzioetatik lehenengo biak 1 balioa, laugarrenak 2 balioa eta beste biak 3 balioa dute. Hortaz, elementu horretarako 1 eta 3 balioen probabilitatea 0.4 izango da --$\frac{2}{5}$, alegia-- eta 2 balioaren probabilitatea 0.2 izango da, marginaleen taulan ikus daitekeen bezala.

Ikasitako eredu probabilistikoa soluzio berriak sortzeko erabil daiteke, posizioz posizio balioak dagokion marginala laginduz; laginketa \code{simulate} funtzioaren bitartez egiten da.

<<UMDA_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
simulate(model , nsim = 2)
@

UMDA erabiliz aurreko ataleko problema ebatz dezakgu. Horretarako, bakarrik hautespen operadoreak eta ereduak ikasteko funtzioak zehaztu behar ditugu --betiko parametroz gain--.

<<umda_gc, echo = -1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , results='hide' , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=10 , fig.height=5>>=
set.seed(2)
args <- list()
args$evaluate             <- gcp$evaluate
args$initial.population   <- pop.small
args$select.subpopulation <- elitist.selection
args$selection.ratio      <- 0.5
args$learn                <- univariateMarginals
args$non.valid            <- 'discard'
args$resources            <- cresource(evaluations = n^2)

umda <- do.call(basic.eda , args)

plot.progress(umda , size = 1.1) + 
  geom_line(aes(y = Current_sol + Current_sd) , col = "gray40" , linetype = 2) +
  geom_line(aes(y = Current_sol - Current_sd)  , col = "gray40" , linetype = 2) + 
  labs(y = "Average fitness")
@

\begin{figure}[t]
\centering
\includegraphics[width=0.75\textwidth] {./Irudiak/umda_gc-1}
\caption{UMDA algoritmoaren progresioa \eng{graph coloring} adibidean. Marra jarraituak populazioko soluzioen bataz-besteko \eng{fitness}a adierazten du; marra etenek, berriz, desbiderazio estandarra adierazten dute. Ikus daiteke populazioak konbergitzen duen heinean soluzioen \eng{fitness}aren bariabilidadea txikiagotzen dela.}\label{fig:umda}
\end{figure}

Bilaketaren progresioa \ref{fig:umda} irudian erakusten da. Marra etenek populazioan dauden soluzioen \eng{fitness}aren desbiderazioa erakusten dute. Eboluzioak aurrera egiten duen heinean, populazioaren dibertsitatea murrizten da eta hau desbiderazioaren txikiagotzean islatzen da; bilaketak 11 kolore darabiltzan soluzio batera konbergitzen du.

Marjinalak zuzenean edozein bektoreekin erabil daitezke; alabaina, balio errealak baditugu, marjinalak zein probabilitate distribuzioarekin modelatuko ditugun erabaki beharko dugu --distribuzio normala, adibidez--. Dena dela, soluzioek murrizketak dituztenean gauzak konplika daitezke; honen adibidea permutazioak dira. 

Permutazio multzo bat badugu, posible da marjinalak estimatzea, baina eredua lagintzen dugunean ez ditugu permutazioak lortuko, balio errepikatuak ager baitaitezke. Hona hemen adibide bat:

<<UMDA_permu_1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
n <- 5
perm.pop <- lapply (1:50 , FUN = function(x) factor(as.numeric(random.permutation(n)) , 
                                                    levels = 1:n))
perm.umda <- univariateMarginals(perm.pop)
simulate(perm.umda)
@

Arazo hau sahiesteko, soluzio berriak lagintzean permutazioetan ditugun murrizketak aintzat hartu behar dira. Beraz, laginketa prozesuan lehenengo elementua ausaz aukeratuko dugu, marjinala erabiliz. 

<<UMDA_permu_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=-1>>=
set.seed(10)
marginals <- perm.umda@prob.table
remaining <- 1:n
probabilities <- marginals[,1]
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- new.element
@

Orain, bigarren elementua aukeratu aurretik, lehenengo posizioan egongo den elementua kendu behar dugu aukeretatik eta marjinalak eguneratu behar ditugu --erabili dugun elementuaren probabilitatea kendu eta normalizatu, gelditzen diren elementuen probabilitateen batura 1 izan dezan--:

<<UMDA_permu_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id , ]
probabilities <- marginals[ , 2]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- c(new.solution , new.element)
@

Prozesua 3. eta 4. elementuak erauzteko errepika dezakegu.

<<UMDA_permu_4, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id , ]
probabilities <- marginals[ , 3]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- c(new.solution , new.element)

id <- which(remaining %in% new.element)
remaining <- remaining [-id]
marginals <- marginals[-id , ]
probabilities <- marginals[ , 3]
probabilities <- probabilities / sum(probabilities)
new.element <- sample(remaining , size = 1 , prob = probabilities)
new.solution <- c(new.solution , new.element)
@

Amaitzeko, permutazioaren azken elementua gelditzen den elementu bakarra izango da.

<<UMDA_permu_5, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
id <- which(remaining %in% new.element)
remaining <- remaining [-id]
new.solution <- c(new.solution , remaining)
new.solution
@

Prozesu honi esker probabilitate marjinalak erabil daitezke permutazioak sortzeko, baina arazo bat dauka; eredua lagintzen dugun bakoitzean probabilitateak aldatzen ditugu eta, hortaz, lagintzen duguna ez da populaziotik ikasi duguna. Beste era batean esanda, populaziotik ateratako \hgl{esentzia} gal genezake. Hau ez gertatzeko, permutazio espazioetan definitutako probabilitate distribuzioak erabil ditzakegu; esate baterako, Mallows eredua, \code{metaheuR} paketean dagoen \code{MallowsModel} objektuak inplementatzen duena.


\section{Swarm Intelligence}\label{sec:swarm}

Eboluzioaren bidez naturak indibiduen diseinuak \hgl{optimizatzeko} gai da; alabaina, hau ez da naturak erabiltzen duen estrategia bakarra. Optimizazio algoritmoak inspiratu dituen beste adibidea bat animalia sozialena da. Zenbait espezietan --intsektuak, batik bat-- banan-banan hartuta, indibiduoak oso izaki sinpleak dira baina, multzoka, ataza konplexuak burutzeko gai dira. Esate baterako, inurriek eta erleek elikagai-iturri onenak aukeratzeko gai dira eta, hauek agortzen direnean, ingurunea esploratzen duten indibiduen kopurua handi dezakete iturri berriak lortzeko; era berean, bizitzeko toki berriak bilatzean toki egokienak aukeratzeko gai dira.

Erabaki guzti horiek ez dira era zentralizatuan hartzen --alegia, ez dago \hgl{nagusi} bat agintzen dunea--. Portaera hauek indibiduoen portaera sinpleen eta, batez ere, indibiduoen arteko komunikazioari esker agertzen dira. Beste era batean esanda, mekanismo sinplei esker kolonia batean dauden indibiduoak autoantolatzen dira.

Portaera hauek dira \eng{swarm intelligence} deritzon arloaren inspirazioa. Kontzpetua lehenengo aldiz robotika arloan proposatu zen \cite{beni1988}, baina laister optimizazio mundura hedatu zen. Izan ere, 90. hamarkadan inurri kolonien optimizazioa --\eng{Ant Colony Optimization}, ingelesez-- proposatu zen \cite{dorigo1992, dorigo1996}.

Hurrengo bi ataletan arlo honetan dauden bi algoritmo ezagunenak aztertuko ditugu, inurri kolonien optimizazioa eta \eng{particle swarm optimization}.



\subsection{\eng{Ant Colony Optimization}}

Inurriek, janaria topatzen dutenean, beraien koloniatik janarira biderik motzena topatzeko gaitasuna dute. Inurri bakar batek ezin du horrelakorik egin baina, taldeka, komunikazio mekanismo sinpleei esker ataza burutzeko gai dira. Erabiltzen den komunikabidea zeharkakoa da, darien molekula mota berezi bati esker: feromonak. Inurriek mugitzen direnean beste inurriek jarrai dezaketen feromona-lorratz bat uzten dute; geroz eta feromona gehiago, orduan eta probabilitate handiagoa datozen inurriak utzitako lorratza jarraitzeko. 

\begin{figure}[t]
\centering
\includegraphics[width=0.75\linewidth]{./Irudiak/ants}
\caption{Feromonaren erabilera. Hasierako egoeran biderik motzena feromonaren bidez markatuta dago. Bidea mozten dugunean, inurriek, eskumara edo ezkerrera joango dira, probabilitate berdinarekin, feromonarik ez baitago ez ezkerrean ez eskuinean. Eskumako bidea luzeagoa da eta, ondorioz, ezkerreko bidearekiko inurri-fluxua txikiagoa da. Denbora igaro ahala, eskumako lorratza ahulduko da; ezkerrekoa, berriz, indartuko da. Honek inurrien erabakia baldintzatuko du, ezkerretik joateko joera handiago sortuz eta, ondorioz, bi bideen arteko diferentziak handituz. Denbora nahiko igarotzen denean eskumako lorratza guztiz galduko da eta inurriak bide motzetik bakarrik joango dira.}
\label{fig:ants}
\end{figure}


Bestaldetik, inurri batek elikagai-iturri bat topatzen duenean, bidetik uzten duen feromona kopurua iturriaren kalitateari egokitzen du; geroz eta kalitate handiagoa, orduan eta feromona gehiago. Sistemaren funtzionamendua ulertzeko kontutan hartu behar dugu feromonak molekula lurrunkorrak direla, hots, denborarekin utzitako lorratzak galtzen direla.

Arau sinple hauek erabiliz inurriek elikagai-iturri onenak aukeratzeko gai dira; are gehiago, elikagai eta inurritegiaren arteko biderik motzena topa dezakete. Mekanismoaren funtzionamendua \ref{fig:ants} irudian ikus daiteke. Hasieran bide motzena feromona lorratzaren bidez markatuta dute inurriek. Bidea mozten badugu, eskuman eta ezkerrean ez dago feromonarik eta, hortaz, inurri batzuk eskumatik eta beste batzuk ezkerretik joango dira, probabilitate berdinarekin. Ezkerreko bidea motzagoa denez, denbora berdinean inurri gehiago igaroko dira, ezkerreko bidean feromona gehiago utziz. Ondorioz, datozen inurriak ezkerretik joateko joera handiago izango dute, bide hori indartuz. Eskumako bidean lorratza apurka-apurka baporatuko da eta, denbora nahiko igarotzen bada, zeharo galduko da.

\eng{Ant Colony Optimization} (ACO) deritzon metaheuristika inurrien mekanismoa hartzen du intuiziotzat. Bere ingurunetik pasiatu beharrean, inurri artifizialak soluzio \hgl{sortzaileak} dira. Beraz, inurri artifizialek soluzioak sortuko dituzte, baina ez edonolakoak; soluzioak aurreko inurriek utzitako lorratzak jarraituz eraikitzen dira. 

Lorratzak feromona ereduen bidez adierazten dira eta bi eratan eguneratzen dira. Alde batetik, inurriek sortutako soluzioen kalitatea --hots, helburu funtzioaren balioa-- feromona gehitzeko erabiltzen da. Bestaldetik, iterazioz iterazio feromona kopuruak txikituko ditugu, molekularen baporazioa simulatuz.

Beraz, bi gauza behar dira ACO algoritmo bat diseinatzeko: feromona eredu bat eta soluzioak sortzeko algoritmo bat. Diseinu sinpleena osagaietan oinarritzen den algoritmo eraikitzaile bat erabiltzea da. Ikus dezagun hau adibide baten bidez.

Demagun MIS problema bat ebatzi nahi dugula. Problema honetarako soluzioak bektore bitarren bidez kodetzen ditugu eta, hortaz, bektorearen posizioak soluzioen osagaitzat har ditzakegu. Posizio bakoitzen bi balio posible daude, 0 edo 1. Inurri batek soluzio bat sortu behar duenenan, lehenik, bektorearen lehenengo posizioko balioa, 0 edo 1, aukeratu beharko du. Horretarako, feromona kopurua hartuko du aintzat, probabilitate handiago esleituz feromona gehiago duen balioari; behin lehenengo posizioko balioa finkaturik, bigarren posiziora pasatuko da eta, era antzerakoan, balio bat esleituko dio. Prozesua soluzio osoa sortu arte errepikatuko da.

Beraz, gure adibidean feromona eredua matrize sinple baten bidez inplementa daiteke non zutabe bakoitzean bektorearen posizio bat izango dugun; matrizeak bi errenkada bakarrik izango ditu, posizio bakoitzeko 0 eta 1 balioek duten feromona kopurua gordetzeko. Feromona eredu mota hau \code{metaheuR} paketean inplementaturik dago, \code{VectorPheromone} klasean. Ereduaren erabilera argitzeko \eng{Maximum Dominating Set} (MDS) problema erabiliko dugu. Laburki, grafo bat emanda, nodoen azpimultzo bat menderatze-multzoa da --\eng{dominating set}, ingelesez-- baldin eta azpimulzoan ez dauden nodo guztiak gutxienez azpimultzoko nodo bati konektatuta badaude; MDS probleman, grafo bat emanik, kardinalitate minimoko menderatze-multzoa topatzean datza. \ref{fig:MDS} irudian problema honetarako hiru soluzio ikus daitezke.


\begin{figure}[t]
\subfigure[Soluzio hau ez da menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_not}
}\qquad
\subfigure[4 tamainako menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_4}
}\qquad
\subfigure[2 tamainako menderatze-multzoa]{
\includegraphics[width=0.3\textwidth] {./Irudiak/MDS_2}
}\\
\caption{Irudiak MDS problemarako 3 soluzio jasotzen ditu --beltzez adierazita dauden nodoak--. Lehenengoa (ezkerrean dagoena), ez da bideragarria, soluzioan dagoen nodo bat soluzioan dauden nodoei konektaturik ez baitago. Bigarren soluzioa bideragarria da, baina ez optimoa. Azken soluzioa optimoa da, ez baitago 1 tamainako soluzio bideragarririk.}\label{fig:MDS}
\end{figure}


<<ACO_MDS_1, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=-1>>=
set.seed(666)
n <- 10
rnd.graph <- aging.ba.game (n , 0.5 , 0 , 2 , directed = FALSE)
mdsp <- mds.problem(graph = rnd.graph)
@

Feromona eredua sortzeko matrizea hasieratu behar dugu. Ohikoena balio finko batekin hasieratzea da. Era honetan osagai guztiak balio berdina dute eta, beraz, guztien probabilitatea berdina izango da. Gogoratu gure adibidean matrizeak bi errenkada izan behar dituela, soluzioak bektore bitarrak baitira.

<<ACO_MDS_2, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
init.trail <- matrix (rep(1 , 2*n) , ncol = n)
evaporation <- 0.9
pheromones <- vectorPheromone(binary = TRUE , initial.trail = init.trail , 
                              evaporation.factor = evaporation)
pheromones@trail
@

Goiko kodean ikus daitekeen bezala, badago beste parametro bat finkatu behar dena, \code{evaporation.fractor}. Parametro horretan pasatzen den balioa lurrunketa faseetan erabiltzen da, matrizean dauden balio guztiak txikiagotzeko; baporazioa \code{evaporate} funtzioa erabiliz egiten da.

<<ACO_MDS_3, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
evaporate(pheromones)
pheromones@trail
evaporate(pheromones)
pheromones@trail
@

Esan dugun bezala, inurriek feromona ereduak soluzioak eraikitzeko erabiltzen dute. Soluzioak \code{build.solution} funtzioaren bitartez egiten da.

<<ACO_MDS_4, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
build.solution(pheromones , 1)
@

Inurriek ingurunetik ibiltzen diren heinean feromona uzten dute eta, era berean, inurri artifizialek soluzioak eraikitzen dutenean feromona kopurua handitzen dute; ereduaren eguneraketa hau \code{update.trail} funtzioa erabiliz egiten da.

<<ACO_MDS_5, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
solution <- build.solution(pheromones , 1)[[1]]
eval <- mdsp$evaluate(solution)
eval
update.trail(object = pheromones , solution = solution , value = eval)
pheromones@trail
@

Ikus daitekeen bezala, zutabe bakoitzean errenkada bati soluzioaren helburu funtzioaren balioa gehitu zaio, hori baita inurriek utzitako lorratza. Elementu guzti hauek batzen baditugu, ACO sinple bat sor dezakegu. Lehenik, problema berri bat sortuko dugu.

<<ACO_MDS_6, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo = -1>>=
set.seed(1)
n <- 100
rnd.graph <- aging.ba.game (n , 0.5 , 0 , 3 , directed = FALSE)
mdsp <- mds.problem(graph = rnd.graph)
init.trail <- matrix (rep(1 , 2*n) , ncol = n)
pheromones <- vectorPheromone(binary = TRUE , initial.trail = init.trail , 
                              evaporation.factor = evaporation)
@

Orain, 500 inurri simulatuko ditugu; bakoitzak soluzio bat sortuko du eta \hgl{bidetik} feromona utziko du. Inurri bakoitza simulatu ondoren feromona \hgl{lurrundu} egiten dugu.

<<ACO_MDS_7, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE>>=
num.ant <- 500
sol.evaluations <- vector()
for (ant in 1:num.ant){
  solution <- mdsp$correct(build.solution(pheromones , 1)[[1]])
  eval <- mdsp$evaluate(solution)
  update.trail(pheromones , solution , eval)
  evaporate(pheromones)
  sol.evaluations <- c(sol.evaluations , eval)
}
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_MDS_8-1}
\caption{ACO sinplearen eboluzioa MDS problema batean.}\label{fig:simple_aco}
\end{figure}

<<ACO_MDS_8, cache=TRUE , prompt=TRUE, message=FALSE , warning=FALSE , echo=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
plot(sol.evaluations , type="l" , xlab="Number of Artificial Ants" , ylab = "Solution evaluation")
@

\ref{fig:simple_aco} irudiak algoritmoaren eboluzioa erakusten du. Irudian ikus daiteke hasieran oso bariabilidade handia dagoela sortutako soluzioen helburu funtzioaren balioan. Alabaina, inurri kopurua handitzen den heinean bariabilidadea murrizten da eta, amaieran, prozedura soluzio bakar batera konbergitzen du. Edonola ere, soluzio hori ez da hasierakoak baino hobea. Kontua da, nahiz eta naturan horrela izan, optimizazioaren ikuspegitik inurri guztiek feromona eredua eguneratzea ez dela hurbilketarik onena; algoritmoa hobetzeko hautespen prozesu bat sartzea komenigarria da.

Ikusi dugun algoritmo sinpleak ez du ondo funtzionatzen, inurri guztiek feromona eguneratzen dutelako. Hori dela eta, beste estrategia erabili ohi da. Inurriak banan-banan simulatu ordez, inurri-kolonia tamaina bat definitzen da eta iterazio bakoitzean inurritegiko inurri guztiek soluzio bat sortzen dute. Gero, bi estrategia ezberdin erabil daitezke:

\begin{itemize}
\item Iterazioko soluziorik onena erabili - Inurriek uneko iterazioan sortutako soluzioen artean onena aukeratzen da eta soluzio hori bakarrik erabiltzen da feromona eredua eguneratzeko. Kasu honetan helburu funtzioaren arabera egitea ez da beharrezkoa, bakarrik soluziorik onena erabiltzen baita eguneraketan. Hori dela eta, ohikoa da balio finko bat erabiltzea eguneraketan.
\item Bilaketan topatutako soluziorik onena - Hainbat kasutan bilaketa areagotzea interesatuko zaigu. Kasu horietan, feromonaren eguneraketa bilaketan zehar topatu den soluziorik onena erabiliz egin daiteke. Aurreko puntuan bezala, eguneraketak ez dauka zergatik izan helburu funtzioaren balioarekiko proportzionala.
\end{itemize}


\begin{ifalgorithm}[t]
\begin{ifpseudo}{Inurri-kolonien algoritmoa}
\item \In\ \texttt{build\_solution}, \texttt{evaporate}, \texttt{add\_pheromone }, \texttt{initalize\_matrix} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{k\_size} koloniaren tamaina
\item \Out\ \texttt{opt\_solution}
\item \texttt{pheromone\_matrix} = \texttt{initialize\_matrix()}
\item \While !\texttt{stop\_criterion()}
\item \T{\textbf{for} \texttt{i} \textbf{in} 1:\texttt{k\_size}}
\item \TT{\texttt{solution} = \texttt{build\_solution(pheromone\_matrix)}}
\item \TT{\texttt{pheromone\_matrix} = \texttt{add\_pheromone(pheromone\_matrix,solution)}}
\item \TT{\If \texttt{solution} \texttt{opt\_solution} baino hobea da}
\item \TTT{\texttt{opt\_solution}=\texttt{solution}}
\item \TT{\EIf}
\item \T{\Done}
\item \T{\texttt{pheromone\_matrix} = \texttt{evaporate(pheromone\_matrix)}}
\item \Done
\end{ifpseudo}
\caption{Inurri-kolonien algoritmoaren sasikodea}\label{alg:ant}
\end{ifalgorithm}


Aldaketa honekin oinarrizko ACO algoritmoaren sasikodea defini dezakegu (ikusi \ref{alg:ant} algoritmoa). \code{basic.aco} funtzioak Oinarrizko ACO-a inplementatzen du eta, hortaz, goiko problema ebazteko erabil dezakegu. Ohiko parametroaz gain, argumentu hauek zehaztu behar dira.

\begin{itemize}
\item \code{nants} - Zenbat inurri artifizial izango ditugu gure kolonian
\item \code{pheromones} - Feromona eredua.
\item \code{update.sol} - Nola eguneratuko dugu feromona eredua. Hiru aukera daude: \code{'best.it'}, iterazio bakoitzean sortutako soluziorik onena; \code{'best.all'}, bilaketan zehar lortutako soluziorik onena edo \code{'all'}, sortutako soluzio guztiak.
\item \code{update.value} - Balio bat finkatzen bada, eguneraketa guztietan balio hori gehitzen da; \code{NULL} bada, helburu funtzioa erabiltzen da. Kontutan hartu problema batzuetan helburu funtzioak negatiboak direla, baina feromona eredu batzuetan balio positiboak eta negatiboak ezin dira nahastu, bestela arazoak egon daitezke probabilitateak kalkulatzean. Hori dela eta, helburu funtzioaren zeinua kontutan hartu behar da feromona eredua hasieratzeko.
\end{itemize}

<<ACO_MDS_10, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(17)
args <- list()
args$evaluate         <- mdsp$evaluate
args$nants            <- 5
init.value            <- 1
initial.trail <- matrix(rep(init.value , 2*n ) , nrow=2)
evapor <- 0.9
pher <- vectorPheromone(binary = TRUE , initial.trail = initial.trail , 
                        evaporation.factor = evapor)
args$pheromones       <- pher
args$update.sol       <- 'best.it'
args$update.value     <- init.value / 10
args$non.valid        <- 'correct'
args$valid            <- mdsp$is.valid
args$correct          <- mdsp$correct

args$resources        <- cresource(iterations = 100)
args$verbose          <- FALSE

results.aco <- do.call(basic.aco , args)
plot.progress(results.aco) + labs(y="Average evaluation")
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_MDS_10-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa MDS problema batean.}\label{fig:basic_aco}
\end{figure}

\ref{fig:basic_aco} irudiak oinarrizko ACO algoritmoaren progresioa jasotzen du. Algoritmo honek soluzio kopuru berdina sortu du, baina aurrekoa ez bezala, iterazioz iterazio soluzioa hobetuz doa. Grafikoan batazbesteko \eng{fitness}-ak bariabilidade handia duela ikus daiteke. Hau da oso kolonia txikia erabili dugulako --5 inurri bakarrik--. Balio hori handitzen badugu, prograsioa ez da hain zaratatsua izango --eta, ziurrenik, emaitzak hobeak izango dira--, baina ebaluazio gehiago beharko ditugu.

ACO algoritmoen mamia soluzio eraikuntza da eta, hortaz, soluzioen osagaien definizioa oso garrantzitsua da; osagaiek problemaren natura kontutan hartzen ez badute, feromona ereduak ez du soluzioen informazioa behar den bezala jasoko. Hau agerian gelditzen da jarraian dagoen adibidean.

Demagun LOP problema bat ebazteko ACO algoritmo bat erabili nahi dugula. Problema honetarako soluzioak permutazioen bidez kodetzen ditugunez, adierazpide honekin diharduen feromona eredu bat behar dugu. Soluzioen eraikuntzan permutazioak sortzeko behar diren aldaketak eginez gero, bektoreekin erabilitako eredua permutazioekin ere erabil dezakegu. Hau da, matrize karratu bat gordeko dugu non posizio bakoitzeko, balio bakoitzari dagokion feromona kopurua gordeko dugu. Gero, soluzioak osatzerakoan, urrats bakoitzean aukeraturik gabe dauden balioetatik bat aukertuko dugu, aukera guztien arteko feromona kopurua kontutan hartuz. Eredu honek UMDA-n ikusi genuen oso matrize antzerakoa erabiltzen du. 

Dena dela, hau ez da aukera bakarra. TSP probleman ikusi genuen permutazioek grafo osoko ziklo Hamiltoniarrak adierazten dituztela. Hau da, $n$ nodoko grafo oso bat badugu, edozein permutazio $n$ nodoak behin eta bakarrik behi bisitatzen dituen ibilbide bat adierazten du. Beraz, permutazioak osatzeko nodoak lotzen dituzten ertzak erabil ditzakegu.

Ideia hau erabiliz beste feromona eredu bat plantea dezakegu. Eredu honek ere matrize karratu bat erabiliko du, baina matrizearen interpretazioa --eta, hortaz, soluzio osaketa-- ezbedina da. Kasu honetan, matrizeak grafoaren ertzak adierazten ditu, alegia, $(i,j)$ posizioan $i$ nodotik $j$ nodora joateari lotutako feromona kopurua izango dugu. Adibidez, 3421 permutazioa badugu, soluzio honi dagozkion matrizeko posizioak dira $(3,4); (4,2)$ eta $(2,1)$ --problemaren arabera, $(1,3)$ posizioa ere erabiltzea komenigarria izan daiteke--.

Bi eredu hauek \code{metaheuR} librutegian inplementaturik daude, \code{PermuPosPheromone} eta  \code{PermuLinkPheromone} objektuetan. Jarraian, bi eredu hauek LOP problema bat ebazteko erabiliko dugu eta emaitzak alderatuko ditugu.

<<ACO_LOP, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(1)
n <- 100
rnd.mat <- matrix(round(runif(n^2)*100) , n)
lop <- lop.problem(matrix = rnd.mat)

args <- list()
args$evaluate         <- lop$evaluate
args$nants            <- 15
init.value            <- 1
initial.trail         <- matrix(rep(init.value , n^2 ) , n)
evapor                <- 0.9
pher                  <- permuLinkPheromone(initial.trail = initial.trail , 
                                            evaporation.factor = evapor)
args$pheromones       <- pher
args$update.sol       <- 'best.it'
args$update.value     <- init.value / 10
args$resources        <- cresource(iterations = 250)
args$verbose          <- FALSE

aco.links <- do.call(basic.aco , args)

args$pheromones       <- permuPosPheromone(initial.trail , evapor)
aco.pos <- do.call(basic.aco , args)

plot.progress (list("Position" = aco.pos , "Link" = aco.links))
@

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_LOP-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa LOP problema batean.}\label{fig:aco_lop}
\end{figure}

\ref{fig:aco_lop} irudiak experimentuaren emaitza erakusten du. Grafikan argi ikus daiteke noden arteko lotruak osagaitzat hartzen direnean, bilaketak ez du aurrera egiten. Osagaiak posizioak direnean, berriz, iterazioz iterazio soluzioa hobetzen da. Honen arrazoia sinplea da: LOP probleman posizio absolutuak dira garrantzitsuena, eta ez zein elementu dagoen zeinen ondoan.

\begin{figure}
\includegraphics[width=\textwidth]{./Irudiak/ACO_TSP-1}
\caption{Oinarrizko ACO algoritmoaren eboluzioa TSP problema batean.}\label{fig:aco_tsp}
\end{figure}

TSP probleman justo kontrakoa gertatzen da, hau da, informazio garrantzitsuena da zein hiri dagoen zeinen ondoan. Hori dela eta, printzipioz, ertzetan oinarritzen den feromona ereduak soluzio hobeak lortuko ditu. Jarrain experimentu hori egingo dugu; emaitzak \ref{fig:aco_tsp} irudian daude.


<<ACO_TSP, cache=TRUE , prompt=TRUE, echo=-1 , message=FALSE , warning=FALSE , fig.path='./Irudiak/' , fig.keep='all' , fig.show='hide' , fig.width=15 , fig.height=5>>=
set.seed(1)
url <- system.file("bays29.xml.zip" , package = "metaheuR")
cost.matrix <- tsplib.parser(url)
n <- ncol(cost.matrix)
tsp <- tsp.problem(cmatrix = cost.matrix)

args <- list()
args$evaluate         <- tsp$evaluate
args$nants            <- 15
init.value            <- 1
initial.trail         <- matrix(rep(init.value , n^2 ) , n)
evapor                <- 0.9
pher                  <- permuLinkPheromone(initial.trail = initial.trail , 
                                            evaporation.factor = evapor)
args$pheromones       <- pher
args$update.sol       <- 'best.it'
args$update.value     <- init.value / 10
args$resources        <- cresource(iterations = 250)
args$verbose          <- FALSE

aco.links <- do.call(basic.aco , args)

args$pheromones       <- permuPosPheromone(initial.trail , evapor)
aco.pos <- do.call(basic.aco , args)

plot.progress (list("Position" = aco.pos , "Link" = aco.links))
@

Orain arte ikusi ditugun adibide guztietan feromonak bakarrik erabiltzen dira soluzioak eraikitzerakoan. Oinarrizko algoritmoan horrela izan arren, problema konkretu bat ebatzi behar denean, posible bada, informazio heuristikoa sartu ohi da. Adibide gisa, TSPrako algoritmo eraikitzaile tipikoan hurrengo hiria hautatzeko hirien arteko distantzia erabiltzen da. Beraz, goiko adibidean hiri batetik bestera joateari dagokion feromona kopurua soilik erabili beharrean, bi hiri horien arteko distantzia ere kontutan har dezakegu.


\subsection{Particle Swarm Optimization}

Intsektu sozialen portaera \textit{swarm} adimenaren adibide tipikoak dira, baina ez dira bakarrak; animali handiagotan ere inspirazioa bila daiteke. Esate baterako, txori-saldotan ehunaka indibiduo batera mugitzen dira beraien arteak talka egin gabe. Multzo horietan ez dago indibiduo bat taldea kontrolatzen duena, txori bakoitzak bere inguruneko txorien portaera aztertzen du, berea egokitzeko. Era horretan, arau sinple batzuk (txori batetik gertuegi banago, urrundu egiten naiz, adibidez) besterik ez dira behar sistema osoa antolatzeko.

\begin{figure}[t]
\centering
\includegraphics[width=0.6\linewidth]{./Irudiak/PSO_1}
\caption{PSO algoritmoak erabiltzen dituen partikulen adibidea. Partikula bakoitzak bere kokapena $(x_i,y_i)$ eta bere abiadura ($\mathbf{v}_i$) du}\label{fig:PSO}
\end{figure}


\textit{Particle Swarm Optimization} (PSO) algoritmoaren inspirazioa animali-talde hauen mugimenduak dira. Gure sisteman bilaketa espazioan mugitzen diren zenbait partikula izango ditugu; partikula bakoitzak kokapen eta abiadura konkretuak izango dituzte. Partikularen kokapenak berak partikulari dagokion soluzioa izango da; abiadurak, hurrengo iterazioan nora mugituko den esango digu. Ikus dezagun adibide sinple bat. \ref{fig:PSO} irudian bi dimentsioko bilaketa espazio bat adierazten da. Bertan, bost partikula ditugu; bakoitzak problemarako soluzio bat adierazten du. Adibidez, $p_1$ partikulak $X=x_1; Y=y_1$ soluzioa adierazten du.

PSO algoritmoan partikulek bilaketa espazioa aztertzen dute, posizio batetik bestera mugituz. Beraz, iterazio bakoitzean partikula guztien kokapena eguneratzen da, beraien abiadura erabiliz. Partikulen abiadurak finko mantentzen baditugu, partikula guztiak infinitura joango dira. Hori ez gertatzeko, iterazio bakoitzean abiadura ere eguneratu behar da; eguneraketa honetan datza, hain zuzen, algoritmoaren gakoa. PSO \textit{swarm intelligence}-ko algoritmo bat denez, indibiduoen arteko (partikulen arteko, kasu honetan) komunikazioa ezinbestekoa da. Komunikazio hau abiadura eguneratze-prozesuan erabiltzen da, partikula bakoitzak bere abiadura eguneratzeko ingurunean dauden partikulak aintzat hartuko baititu. 

Beraz, algoritmoa aplikatzeko ingurune kontzeptua definitu behar dugu. PSO-n, ingurune kontzeptua ez da bilaketa lokalean erabiltzen den berdina, partikula bakoitzaren ingurunea aurrez aurretik ezarritakoa baita; ez du partikularen kokapenarekin zerikusirik, alegia. Partikula bakoitzaren ingurunea grafo baten bidez adieraz daiteke, non bi partikula konektatuta dauden baldin eta bakarrik baldin bata bestearen ingurunean badaude. Lehenengo hurbilketa grafo osoa erabiltzea da, hots, edozein partikularen ingurunean beste gainontzeko partikula guztiak egongo dira; grafo osoa erabili beharrean, beste zenbait topologia ere erabil daitezke (eraztunak, izarrak, toroideak, etab.).

Partikula baten abiadura eguneratzeko bi elementu erabiltzen dira. Alde batetik, partikula horrek bisitatu duen soluziorik onena, hau da, bere \zkk arrakasta pertsonala\skk. Soluzio honi ingelesez \textit{personal best} deritzo, eta $\mathbf{p}_i$ sinboloaren bidez adieraziko dugu. Bestaldetik, ingurunean dauden partikulen arrakasta ere kontutan hartzen da, partikularen ingurunean dauden beste partikulek lortu duten soluziorik onena, alegia. Soluzio honi ingelesez \textit{global best}\footnote{Ingurunea definitzeko grafo osoa erabiltzen ez bada, partikula baten ingurunean lortutako soluziorik onenari \textit{global best} baino \textit{local best} esaten zaio} deritzo, eta $\mathbf{p}_g$ sinboloaren bidez adieraziko dugu.

Hau dena kontutan hartuta, $i$. partikulak $t$ iterazioan erabiliko duen abiadura aurreko iterazioan erabilitakoa ondoko ekuazioaren bidez kalkulatuko dugu:

\begin{align*}
\mathbf{v}_i(t) = \mathbf{v}_i(t-1) + \rho_1 C_1 [\mathbf{p}_i - \mathbf{x}_i(t-1)] + \rho_2 C_2 [\mathbf{p}_g - \mathbf{x}_i(t-1)]
\end{align*}

Ekuazioan bi konstante ditugu, $C_1$ eta $C_2$; balio hauek partikulak eta ingurunean topatutako soluzioen eragina kontrolatzeko erabiltze dira. Konstante hauetaz gain, bi ausazko aldagai ditugu, $\rho_1$ eta $\rho_2$. Bi aldagai hauek ausazko balioak hartzen dituzte $[0,1]$ tartean. 

Lortutako abiadura bektore bat da. Arazoak saihesteko, bektore horren modulua mugatuta dago, aurrez aurretik abiadura maximoa ezarriz. Kalkulatutako abiaduraren modulua handiagoa bada, balio maximora eramaten da.

Behin uneko iterazioaren abiadura kalkulatuta, abiadura partikularen kokapena eguneratzeko erabiltzen da:

\begin{align*}
\mathbf{x}_i(t) = \mathbf{x}_i(t-1) + \mathbf{v}_i(t-1)
\end{align*}

Iterazio bakoitzean lortutako soluzioak ebaluatu eta, beharrezkoa bada, partikulen \textit{personal} eta \textit{global best} eguneratu behar dira. Pasu guzti hauek \ref{alg:pso} algoritmoan biltzen dira.


\begin{ifalgorithm}[t]\label{alg:pso}
\begin{ifpseudo}{PSO algoritmoa}
\item \In\ \texttt{initialize\_position}, \texttt{initialize\_velocity}, \texttt{update\_velocity}, \texttt{evaluate} eta \texttt{stop\_criterion} operadoreak
\item \In\ \texttt{num\_particles} partikula kopurua
\item \Out\ \texttt{opt\_solution}
\item \texttt{gbest = p[1]}
\item \textbf{for each} \texttt{i} \textbf{in} \texttt{1:num\_particles} \Do
\item \T{\texttt{p[i]=initialize\_position(i)}}
\item \T{\texttt{v[i]=initialize\_velocity(i)}}
\item \T{\texttt{pbest[i]=p[i]}}
\item \T{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TT{\texttt{gbest = p[i]}}
\item \T{\EIf}
\item \Done
\item \While !\texttt{stop\_criterion()} \Do
\item \T{\textbf{for each} \texttt{i} \textbf{in} \texttt{particle\_set}}
\item \T{\Do}
\item \TT{\texttt{v[i]} = update\_velocity(i)}
\item \TT{\texttt{p[i] = p[i] + v[i]}}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(pbest[i])}}
\item \TTT{\texttt{pbest[i]}=\texttt{p[i]}}
\item \TT{\EIf}
\item \TT{\If \texttt{evaluate(p[i])<evaluate(gbest)}}
\item \TTT{\texttt{gbest}=\texttt{p[i]}}
\item \TT{\EIf}
\item \T{\Done}
\item \Done
\item \texttt{opt\_solution = gbest}
\end{ifpseudo}
\caption{\textit{Particle Swarm Optimization} algoritmoaren sasikodea}
\end{ifalgorithm}




%\subsection{Oinarrizko Egiturak}
%\subsubsection{Soluzioen errepresentazioa: Indibiduoak}
%\subsubsection{Populazioaren hasieraketa}
%\subsubsection{Aukeraketa irizpideak}
%Roulette-Wheel, Tournament, Rank-Based Selection...
%\subsubsection{Soluzioen berrien sorrera prozedurak}
%Algoritmoaren menpekoa, GAk mutation and crossover, EDAk learn a model, and sample solutions.
%\subsubsection{Gelditze Irizpideak}


\bibliographystyle{plain}
\bibliography{references}

\end{document}